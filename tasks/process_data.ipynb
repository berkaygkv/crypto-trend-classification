{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e13f7d",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f6b702",
   "metadata": {
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "initial_return_thresh = 0.1\n",
    "upstream = {\n",
    "    \"data_saving\": {\n",
    "        \"data_train\": \"C:\\\\Users\\\\berkayg\\\\Desktop\\\\Coding env\\\\crypto-prediction-project\\\\products\\\\data\\\\raw_train_data.csv\",\n",
    "        \"data_validation\": \"C:\\\\Users\\\\berkayg\\\\Desktop\\\\Coding env\\\\crypto-prediction-project\\\\products\\\\data\\\\raw_validation_data.csv\",\n",
    "    }\n",
    "}\n",
    "product = {\n",
    "    \"nb\": \"C:\\\\Users\\\\berkayg\\\\Desktop\\\\Coding env\\\\crypto-prediction-project\\\\products\\\\notebooks\\\\process_data.ipynb\",\n",
    "    \"data_train\": \"C:\\\\Users\\\\berkayg\\\\Desktop\\\\Coding env\\\\crypto-prediction-project\\\\products\\\\data\\\\processed_train_data.csv\",\n",
    "    \"data_validation\": \"C:\\\\Users\\\\berkayg\\\\Desktop\\\\Coding env\\\\crypto-prediction-project\\\\products\\\\data\\\\processed_validation_data.csv\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from datetime import datetime\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import plotly.express as px\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "#import talib\n",
    "import ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Close', 'Volume', 'Price', 'trend_ema_fast', 'trend_ema_slow', 'trend_sma_fast', 'trend_sma_slow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    df = pd.read_csv(path, header=[0, 1],index_col=[0], parse_dates=[0])\n",
    "    df = df.droplevel(0, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_data(upstream[\"data_saving\"][\"data_train\"])\n",
    "df_validation = read_data(upstream[\"data_saving\"][\"data_validation\"])\n",
    "df_total = pd.concat([df_validation, df_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _action(x):\n",
    "    if not pd.isnull(x[\"loc_min\"]):\n",
    "        return \"buy\"\n",
    "    elif not pd.isnull(x[\"loc_max\"]):\n",
    "        return \"sell\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_extremas(dataframe, **kwargs):\n",
    "    \"\"\"Finds local maximas/minimas in the series\n",
    "    Returns: List of extremas indices and dataframe with extremas added\n",
    "    \"\"\"\n",
    "    df = dataframe.copy()\n",
    "    df[\"returns\"] = df[\"Close\"].pct_change().fillna(0) * 100\n",
    "    df[\"returns\"] = df[\"returns\"].shift(-1)\n",
    "    df = df.iloc[:-1]\n",
    "    \n",
    "    df['loc_max'] = df.iloc[find_peaks(df.reset_index(drop=True)['Close'].to_numpy(), **kwargs)[0]]['Close']\n",
    "    df['loc_min'] = df.iloc[find_peaks(df.reset_index(drop=True)['Close'].to_numpy() * -1, **kwargs)[0]]['Close']\n",
    "    \n",
    "    idx_with_mins = np.where(df['loc_min'] > 0)[0]\n",
    "    idx_with_maxs = np.where(df['loc_max'] > 0)[0]\n",
    "    idx_concat = np.concatenate([idx_with_mins, idx_with_maxs])\n",
    "    \n",
    "    first_idx_bool = idx_with_mins.min() > idx_with_maxs.min()\n",
    "    if first_idx_bool and 0 not in idx_concat:\n",
    "        idx_with_mins = np.append(0, idx_with_mins)\n",
    "        df.iloc[0, df.columns.get_loc(\"loc_min\")] = df.iloc[0, df.columns.get_loc(\"Close\")]\n",
    "    \n",
    "    elif not first_idx_bool and 0 not in idx_concat:\n",
    "        idx_with_maxs = np.append(0, idx_with_maxs)\n",
    "        df.iloc[0, df.columns.get_loc(\"loc_max\")] = df.iloc[0, df.columns.get_loc(\"Close\")]\n",
    "    \n",
    "    return idx_with_maxs, idx_with_mins, idx_concat, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_extremas(df, idx_concat,thresh=1):\n",
    "    \"\"\"Remove unsignificant peaks and dips\n",
    "    Returns: Dataframe\n",
    "    \"\"\"\n",
    "    df[\"idx\"] = ((df[\"loc_min\"].isnull()) & (df[\"loc_max\"].isnull())).cumsum()\n",
    "    df[\"idx\"] = np.arange(0, df.shape[0])\n",
    "    df[\"count\"] = np.arange(0, df.shape[0])\n",
    "    df[\"count\"] = (df[\"count\"].isin(idx_concat)).cumsum()\n",
    "    df['cum_return'] = df.sort_index(ascending=False).groupby('count')['returns'].transform(np.cumsum)#.shift()\n",
    "    df.loc[(df[\"loc_min\"].isnull() == False) & (abs(df[\"cum_return\"]) < thresh), \"loc_min\"] = np.nan\n",
    "    df.loc[(df[\"loc_max\"].isnull() == False) & (abs(df[\"cum_return\"]) < thresh), \"loc_max\"] = np.nan\n",
    "    df[\"action\"] = df.apply(_action, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(df):\n",
    "    hover_data = {\"Close\": True, \"Date\": True, \"returns\":True, \"cum_return\":True, \"idx\":True, \"count\":True}\n",
    "    fig_obj = px.line(x=\"Date\", y=\"Close\", data_frame=df.reset_index(), hover_data=hover_data)\n",
    "\n",
    "    extrema_min = px.scatter(x=\"Date\", y=\"loc_min\", data_frame=df.reset_index(), hover_data=hover_data)\n",
    "    extrema_min.update_traces(marker=dict(color='green'))\n",
    "\n",
    "    extrema_max = px.scatter(x=\"Date\", y=\"loc_max\", data_frame=df.reset_index(), hover_data=hover_data)\n",
    "    extrema_max.update_traces(marker=dict(color='red'))\n",
    "\n",
    "    fig = fig_obj.data + extrema_min.data + extrema_max.data\n",
    "    return go.Figure(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, symbol, prominence=0.8, thresh=0.5):\n",
    "    print(f\"CONFIG: Symbol: {symbol} - Prominence: {prominence} - Thresh: {thresh}\")\n",
    "    try:\n",
    "        df = df[[symbol]].droplevel(axis=1, level=0)\n",
    "    except:\n",
    "        pass\n",
    "    _, _, idx_concat, df = find_extremas(df, prominence=prominence)\n",
    "    df = optimize_extremas(df, idx_concat, thresh=thresh)\n",
    "    fig = plot_series(df)\n",
    "    print(df.action.value_counts())\n",
    "    return idx_concat, df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"action\"]], fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x, y):\n",
    "    \"\"\"\n",
    "    performs linear regression given x and y. outputs regression coefficient\n",
    "    \"\"\"\n",
    "    #fit linear regression\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x, y)\n",
    "    \n",
    "    return lr.coef_[0][0]\n",
    "\n",
    "def n_day_regression(n, df, idxs):\n",
    "    \"\"\"\n",
    "    n day regression.\n",
    "    \"\"\"\n",
    "    #variable\n",
    "    _varname_ = f'{n}_reg'\n",
    "    df[_varname_] = np.nan\n",
    "\n",
    "    for idx in idxs:\n",
    "        if idx > n:\n",
    "            \n",
    "            y = df['Close'][idx - n: idx].to_numpy()\n",
    "            x = np.arange(0, n)\n",
    "            #reshape\n",
    "            y = y.reshape(y.shape[0], 1)\n",
    "            x = x.reshape(x.shape[0], 1)\n",
    "            #calculate regression coefficient \n",
    "            coef = linear_regression(x, y)\n",
    "            df.iloc[idx, df.columns.get_loc(_varname_)] = coef #add the new value\n",
    "            \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Supertrend(df, atr_period, multiplier):\n",
    "    \n",
    "    high = df['High']\n",
    "    low = df['Low']\n",
    "    close = df['Close']\n",
    "    center = df['center']\n",
    "    \n",
    "    # calculate ATR\n",
    "    price_diffs = [high - low, \n",
    "                   high - close.shift(), \n",
    "                   close.shift() - low]\n",
    "    true_range = pd.concat(price_diffs, axis=1)\n",
    "    true_range = true_range.abs().max(axis=1)\n",
    "    # default ATR calculation in supertrend indicator\n",
    "    atr = true_range.ewm(alpha=1/atr_period,min_periods=atr_period).mean() \n",
    "    # df['atr'] = df['tr'].rolling(atr_period).mean()\n",
    "    \n",
    "    # HL2 is simply the average of high and low prices\n",
    "    hl2 = (high + low) / 2\n",
    "    # upperband and lowerband calculation\n",
    "    # notice that final bands are set to be equal to the respective bands\n",
    "    # final_upperband = upperband = hl2 + (multiplier * atr)\n",
    "    # final_lowerband = lowerband = hl2 - (multiplier * atr)\n",
    "\n",
    "    final_upperband = upperband = center + (multiplier * atr)\n",
    "    final_lowerband = lowerband = center - (multiplier * atr)\n",
    "\n",
    "    \n",
    "    # initialize Supertrend column to True\n",
    "    supertrend = [True] * len(df)\n",
    "    \n",
    "    for i in range(1, len(df.index)):\n",
    "        curr, prev = i, i-1\n",
    "        \n",
    "        # if current close price crosses above upperband\n",
    "        if close[curr] > final_upperband[prev]:\n",
    "            supertrend[curr] = True\n",
    "        # if current close price crosses below lowerband\n",
    "        elif close[curr] < final_lowerband[prev]:\n",
    "            supertrend[curr] = False\n",
    "        # else, the trend continues\n",
    "        else:\n",
    "            supertrend[curr] = supertrend[prev]\n",
    "            \n",
    "            # adjustment to the final bands\n",
    "            if supertrend[curr] == True and final_lowerband[curr] < final_lowerband[prev]:\n",
    "                final_lowerband[curr] = final_lowerband[prev]\n",
    "            if supertrend[curr] == False and final_upperband[curr] > final_upperband[prev]:\n",
    "                final_upperband[curr] = final_upperband[prev]\n",
    "\n",
    "        # to remove bands according to the trend direction\n",
    "        if supertrend[curr] == True:\n",
    "            final_upperband[curr] = np.nan\n",
    "        else:\n",
    "            final_lowerband[curr] = np.nan\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'Supertrend': supertrend,\n",
    "        'Final Lowerband': final_lowerband,\n",
    "        'Final Upperband': final_upperband\n",
    "    }, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supertrend_processing(df):\n",
    "    if \"action\" in df.columns:\n",
    "        df = df.drop(columns=[\"action\"])\n",
    "    \n",
    "\n",
    "    df[\"ph_arg\"] = df[\"High\"].rolling(2).apply(lambda x: np.argmax(x))\n",
    "    df[\"ph_arg_rev\"] = df[\"High\"].sort_index(ascending=False).rolling(2).apply(lambda x: np.argmax(x))\n",
    "    df[\"ph\"] = (df[\"ph_arg\"] == 1) & (df[\"ph_arg_rev\"] == 1)\n",
    "    df[\"ph\"] = df.apply(lambda x: x[\"High\"] if x[\"ph\"] == 1 else np.nan, axis=1)\n",
    "\n",
    "    df[\"pl_arg\"] = df[\"Low\"].rolling(2).apply(lambda x: np.argmin(x))\n",
    "    df[\"pl_arg_rev\"] = df[\"Low\"].sort_index(ascending=False).rolling(2).apply(lambda x: np.argmin(x))\n",
    "    df[\"pl\"] = (df[\"pl_arg\"] == 1) & (df[\"pl_arg_rev\"] == 1)\n",
    "    df[\"pl\"] = df.apply(lambda x: x[\"Low\"] if x[\"pl\"] == 1 else np.nan, axis=1)\n",
    "\n",
    "    df.drop(columns=[\"ph_arg_rev\", \"ph_arg\", \"pl_arg_rev\", \"pl_arg\"], inplace=True)\n",
    "    df = extract_pivot_centers(df)\n",
    "    df[\"ph\"] = np.where(df[\"ph\"].isnull(), 0, 1)\n",
    "    df[\"pl\"] = np.where(df[\"pl\"].isnull(), 0, 1)\n",
    "\n",
    "    atr_period = 3\n",
    "    high = df['High']\n",
    "    low = df['Low']\n",
    "    close = df['Close']\n",
    "    center = df['center']\n",
    "    # calculate ATR\n",
    "    price_diffs = [high - low, \n",
    "                   high - close.shift(), \n",
    "                   close.shift() - low]\n",
    "    true_range = pd.concat(price_diffs, axis=1)\n",
    "    true_range = true_range.abs().max(axis=1)\n",
    "    # default ATR calculation in supertrend indicator\n",
    "    atr = true_range.ewm(alpha=1/atr_period,min_periods=atr_period).mean() \n",
    "    df[\"atr\"] = atr\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pivot_centers(df):\n",
    "    df[\"center\"] = np.nan\n",
    "    center = np.nan\n",
    "    for i, k in enumerate(df.iterrows()):\n",
    "        ph = k[1][\"ph\"]\n",
    "        pl = k[1][\"pl\"]\n",
    "        if not pd.isnull(ph):\n",
    "            lastpp = ph\n",
    "            center = lastpp\n",
    "        elif not pd.isnull(pl):\n",
    "            lastpp = pl\n",
    "            center = lastpp\n",
    "        else:\n",
    "            k[1][\"center\"] = center\n",
    "            continue\n",
    "\n",
    "        if pd.isnull(center):\n",
    "            center = (center * 2 + lastpp) / 3\n",
    "\n",
    "        k[1][\"center\"] = center\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df_source):\n",
    "    df = ta.add_all_ta_features(df_source.drop(columns=[\"action\"]), open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\")\n",
    "    \n",
    "    epsilon = 10e-10\n",
    "    high = df[\"High\"] - df[\"Low\"]\n",
    "    close = df[\"Close\"] - df[\"Low\"]\n",
    "    df[\"Price\"] = close/(high + epsilon)\n",
    "\n",
    "    \n",
    "    df = df[columns]\n",
    "    df = n_day_regression(5, df, np.arange(0, df.shape[0]))\n",
    "    df = n_day_regression(10, df, np.arange(0, df.shape[0]))\n",
    "    df = n_day_regression(50, df, np.arange(0, df.shape[0]))\n",
    "\n",
    "    df['action'] = df_source['action'].map(lambda x: 0 if x==\"neutral\" else 1)\n",
    "    #df_processed['action'] = df_symbol['action'].map(action_dictionary)\n",
    "    df[\"ema\"] = df[\"trend_ema_fast\"] / df[\"trend_ema_slow\"]\n",
    "    df[\"sma\"] = df[\"trend_sma_fast\"] / df[\"trend_sma_slow\"]\n",
    "\n",
    "\n",
    "    # import talib\n",
    "    # df[\"RSI\"] = talib.RSI(df_source[\"Close\"])\n",
    "    df[\"Stock_RSI\"] = ta.momentum.StochRSIIndicator(df[\"Close\"], window=5).stochrsi()\n",
    "    df = df.dropna().drop(columns=[\"trend_ema_fast\", \"trend_ema_slow\", \"trend_sma_slow\", \"trend_sma_fast\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supertrend = supertrend_processing(df_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sum = lambda x: max(0, x.sum() - 1)\n",
    "look_back_pivots = df_supertrend.rolling(5).agg({\"ph\": custom_sum, \"pl\": custom_sum}).add_prefix('5_step_lookback_').fillna(0)\n",
    "df_supertrend = pd.concat([df_supertrend, look_back_pivots], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_concat, df_symbol, fig_symbol = prepare_data(df_train, \"VIDTUSDT\", prominence=None, thresh=initial_return_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_concat_valid, df_symbol_valid, fig_symbol_valid = prepare_data(df_validation, \"VIDTUSDT\", prominence=None, thresh=initial_return_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dictionary = {\n",
    "    \"buy\": 1,\n",
    "    \"neutral\": 0,\n",
    "    \"sell\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_valid = process_data(df_symbol_valid)\n",
    "df_processed_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = process_data(df_symbol)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.concat([df_processed, df_supertrend[[\"ph\", \"pl\", \"center\", \"5_step_lookback_ph\", \"5_step_lookback_pl\", \"atr\"]]], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_valid = pd.concat([df_processed_valid, df_supertrend[[\"ph\", \"pl\", \"center\", \"5_step_lookback_ph\", \"5_step_lookback_pl\", \"atr\"]]], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.to_csv(product[\"data_train\"])\n",
    "df_processed_valid.to_csv(product[\"data_validation\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7aa3e32ad1ac443041e179702ff775d0d6aade27c9973dce7d8a7f55c4f1197d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "papermill": {
   "parameters": {
    "initial_return_thresh": 0.1,
    "product": {
     "data_train": "C:\\Users\\berkayg\\Desktop\\Coding env\\crypto-prediction-project\\products\\data\\processed_train_data.csv",
     "data_validation": "C:\\Users\\berkayg\\Desktop\\Coding env\\crypto-prediction-project\\products\\data\\processed_validation_data.csv",
     "nb": "C:\\Users\\berkayg\\Desktop\\Coding env\\crypto-prediction-project\\products\\notebooks\\process_data.ipynb"
    },
    "upstream": {
     "data_saving": {
      "data_train": "C:\\Users\\berkayg\\Desktop\\Coding env\\crypto-prediction-project\\products\\data\\raw_train_data.csv",
      "data_validation": "C:\\Users\\berkayg\\Desktop\\Coding env\\crypto-prediction-project\\products\\data\\raw_validation_data.csv"
     }
    }
   }
  },
  "ploomber": {
   "injected_manually": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
